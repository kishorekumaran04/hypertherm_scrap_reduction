{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU/TPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '':\n",
    "    print(f'Found GPU at: {device_name}')\n",
    "else:\n",
    "    print('No GPU found, using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data\n",
    "nestdf = pd.read_csv('Nest.csv')\n",
    "partavgdf = pd.read_csv('Part_Avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ixJobSummary</th>\n",
       "      <th>fStrategies</th>\n",
       "      <th>dLengthUsed_Avg</th>\n",
       "      <th>dWidthUsed_Avg</th>\n",
       "      <th>dPartArea_Job</th>\n",
       "      <th>dTrueAreaRectified_Job</th>\n",
       "      <th>dLength_Avg</th>\n",
       "      <th>dWidth_Avg</th>\n",
       "      <th>dArea_Avg</th>\n",
       "      <th>cNested_Avg</th>\n",
       "      <th>fExtShape_Avg</th>\n",
       "      <th>dExtArea_Avg</th>\n",
       "      <th>dExtBoundaryDist_Avg</th>\n",
       "      <th>dExtContainedDist_Avg</th>\n",
       "      <th>dLgIntArea_Avg</th>\n",
       "      <th>dLgIntBoundaryDist_Avg</th>\n",
       "      <th>dLgIntContainedDist_Avg</th>\n",
       "      <th>dLgExtConArea_Avg</th>\n",
       "      <th>dLgExtConBoundaryDist</th>\n",
       "      <th>dLgExtConContainedDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130032</td>\n",
       "      <td>0</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>95.990000</td>\n",
       "      <td>519.0404</td>\n",
       "      <td>23037.600000</td>\n",
       "      <td>11.214286</td>\n",
       "      <td>7.588371</td>\n",
       "      <td>58.148629</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145075</td>\n",
       "      <td>8</td>\n",
       "      <td>108.453240</td>\n",
       "      <td>39.263200</td>\n",
       "      <td>18389.9746</td>\n",
       "      <td>21573.573062</td>\n",
       "      <td>38.347309</td>\n",
       "      <td>12.843400</td>\n",
       "      <td>475.076800</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>496.283591</td>\n",
       "      <td>6.026536</td>\n",
       "      <td>39.581636</td>\n",
       "      <td>14.593373</td>\n",
       "      <td>0.535145</td>\n",
       "      <td>2.846391</td>\n",
       "      <td>12.247745</td>\n",
       "      <td>0.341673</td>\n",
       "      <td>0.728891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233110</td>\n",
       "      <td>8</td>\n",
       "      <td>38.709400</td>\n",
       "      <td>35.736100</td>\n",
       "      <td>879.9165</td>\n",
       "      <td>1383.322989</td>\n",
       "      <td>37.702200</td>\n",
       "      <td>20.209600</td>\n",
       "      <td>439.958200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>439.958200</td>\n",
       "      <td>9.161500</td>\n",
       "      <td>36.520700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.162600</td>\n",
       "      <td>2.761000</td>\n",
       "      <td>12.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>286531</td>\n",
       "      <td>8</td>\n",
       "      <td>69.701700</td>\n",
       "      <td>60.558550</td>\n",
       "      <td>5992.2342</td>\n",
       "      <td>9448.707993</td>\n",
       "      <td>17.103650</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>191.540050</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>193.776600</td>\n",
       "      <td>6.589750</td>\n",
       "      <td>20.581050</td>\n",
       "      <td>0.279550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>35.632250</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504531</td>\n",
       "      <td>0</td>\n",
       "      <td>6.807000</td>\n",
       "      <td>38.006900</td>\n",
       "      <td>198.8594</td>\n",
       "      <td>258.712968</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>198.859400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>198.859400</td>\n",
       "      <td>2.644400</td>\n",
       "      <td>37.148100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790931</th>\n",
       "      <td>2583832</td>\n",
       "      <td>0</td>\n",
       "      <td>143.770400</td>\n",
       "      <td>94.319500</td>\n",
       "      <td>3562.2303</td>\n",
       "      <td>13560.352243</td>\n",
       "      <td>52.203125</td>\n",
       "      <td>32.046875</td>\n",
       "      <td>815.453875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1175.660175</td>\n",
       "      <td>15.350675</td>\n",
       "      <td>52.728425</td>\n",
       "      <td>355.015300</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790932</th>\n",
       "      <td>548877</td>\n",
       "      <td>4</td>\n",
       "      <td>34.513950</td>\n",
       "      <td>55.300350</td>\n",
       "      <td>2898.6813</td>\n",
       "      <td>4526.656120</td>\n",
       "      <td>23.053571</td>\n",
       "      <td>13.199986</td>\n",
       "      <td>273.049857</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>296.410943</td>\n",
       "      <td>6.052186</td>\n",
       "      <td>25.126200</td>\n",
       "      <td>3.782143</td>\n",
       "      <td>0.233057</td>\n",
       "      <td>1.326471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790933</th>\n",
       "      <td>2420784</td>\n",
       "      <td>8</td>\n",
       "      <td>83.969400</td>\n",
       "      <td>33.398500</td>\n",
       "      <td>1732.8873</td>\n",
       "      <td>2804.452006</td>\n",
       "      <td>83.057750</td>\n",
       "      <td>4.540683</td>\n",
       "      <td>288.814567</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>331.347183</td>\n",
       "      <td>2.041967</td>\n",
       "      <td>83.173917</td>\n",
       "      <td>10.515283</td>\n",
       "      <td>0.609483</td>\n",
       "      <td>2.738883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790934</th>\n",
       "      <td>2302130</td>\n",
       "      <td>8</td>\n",
       "      <td>80.844067</td>\n",
       "      <td>54.065133</td>\n",
       "      <td>7208.6328</td>\n",
       "      <td>14136.765442</td>\n",
       "      <td>43.584450</td>\n",
       "      <td>40.175350</td>\n",
       "      <td>693.526650</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1308.887900</td>\n",
       "      <td>15.457300</td>\n",
       "      <td>51.257850</td>\n",
       "      <td>504.934150</td>\n",
       "      <td>7.507200</td>\n",
       "      <td>22.396550</td>\n",
       "      <td>61.498750</td>\n",
       "      <td>1.939500</td>\n",
       "      <td>9.697650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790935</th>\n",
       "      <td>382952</td>\n",
       "      <td>0</td>\n",
       "      <td>37.081600</td>\n",
       "      <td>32.037000</td>\n",
       "      <td>1883.8126</td>\n",
       "      <td>2903.640657</td>\n",
       "      <td>22.099367</td>\n",
       "      <td>18.409433</td>\n",
       "      <td>313.968767</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>313.968767</td>\n",
       "      <td>7.825233</td>\n",
       "      <td>24.060967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790936 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ixJobSummary  fStrategies  dLengthUsed_Avg  dWidthUsed_Avg  \\\n",
       "0              130032            0       240.000000       95.990000   \n",
       "1              145075            8       108.453240       39.263200   \n",
       "2              233110            8        38.709400       35.736100   \n",
       "3              286531            8        69.701700       60.558550   \n",
       "4              504531            0         6.807000       38.006900   \n",
       "...               ...          ...              ...             ...   \n",
       "1790931       2583832            0       143.770400       94.319500   \n",
       "1790932        548877            4        34.513950       55.300350   \n",
       "1790933       2420784            8        83.969400       33.398500   \n",
       "1790934       2302130            8        80.844067       54.065133   \n",
       "1790935        382952            0        37.081600       32.037000   \n",
       "\n",
       "         dPartArea_Job  dTrueAreaRectified_Job  dLength_Avg  dWidth_Avg  \\\n",
       "0             519.0404            23037.600000    11.214286    7.588371   \n",
       "1           18389.9746            21573.573062    38.347309   12.843400   \n",
       "2             879.9165             1383.322989    37.702200   20.209600   \n",
       "3            5992.2342             9448.707993    17.103650   18.125000   \n",
       "4             198.8594              258.712968    37.000000    5.800000   \n",
       "...                ...                     ...          ...         ...   \n",
       "1790931      3562.2303            13560.352243    52.203125   32.046875   \n",
       "1790932      2898.6813             4526.656120    23.053571   13.199986   \n",
       "1790933      1732.8873             2804.452006    83.057750    4.540683   \n",
       "1790934      7208.6328            14136.765442    43.584450   40.175350   \n",
       "1790935      1883.8126             2903.640657    22.099367   18.409433   \n",
       "\n",
       "          dArea_Avg  cNested_Avg  fExtShape_Avg  dExtArea_Avg  \\\n",
       "0         58.148629            1              9      0.000000   \n",
       "1        475.076800            4              5    496.283591   \n",
       "2        439.958200            2              0    439.958200   \n",
       "3        191.540050           12              0    193.776600   \n",
       "4        198.859400            1              0    198.859400   \n",
       "...             ...          ...            ...           ...   \n",
       "1790931  815.453875            1              2   1175.660175   \n",
       "1790932  273.049857            4              3    296.410943   \n",
       "1790933  288.814567            1             16    331.347183   \n",
       "1790934  693.526650            5              0   1308.887900   \n",
       "1790935  313.968767            2             13    313.968767   \n",
       "\n",
       "         dExtBoundaryDist_Avg  dExtContainedDist_Avg  dLgIntArea_Avg  \\\n",
       "0                    0.000000               0.000000        0.000000   \n",
       "1                    6.026536              39.581636       14.593373   \n",
       "2                    9.161500              36.520700        0.000000   \n",
       "3                    6.589750              20.581050        0.279550   \n",
       "4                    2.644400              37.148100        0.000000   \n",
       "...                       ...                    ...             ...   \n",
       "1790931             15.350675              52.728425      355.015300   \n",
       "1790932              6.052186              25.126200        3.782143   \n",
       "1790933              2.041967              83.173917       10.515283   \n",
       "1790934             15.457300              51.257850      504.934150   \n",
       "1790935              7.825233              24.060967        0.000000   \n",
       "\n",
       "         dLgIntBoundaryDist_Avg  dLgIntContainedDist_Avg  dLgExtConArea_Avg  \\\n",
       "0                      0.000000                 0.000000           0.000000   \n",
       "1                      0.535145                 2.846391          12.247745   \n",
       "2                      0.000000                 0.000000          60.162600   \n",
       "3                      0.000000                 0.125000          35.632250   \n",
       "4                      0.000000                 0.000000           0.000000   \n",
       "...                         ...                      ...                ...   \n",
       "1790931                7.125000                15.062500           0.000000   \n",
       "1790932                0.233057                 1.326471           0.000000   \n",
       "1790933                0.609483                 2.738883           0.000000   \n",
       "1790934                7.507200                22.396550          61.498750   \n",
       "1790935                0.000000                 0.000000           0.000000   \n",
       "\n",
       "         dLgExtConBoundaryDist  dLgExtConContainedDist  \n",
       "0                     0.000000                0.000000  \n",
       "1                     0.341673                0.728891  \n",
       "2                     2.761000               12.675600  \n",
       "3                     2.375000                4.500000  \n",
       "4                     0.000000                0.000000  \n",
       "...                        ...                     ...  \n",
       "1790931               0.000000                0.000000  \n",
       "1790932               0.000000                0.000000  \n",
       "1790933               0.000000                0.000000  \n",
       "1790934               1.939500                9.697650  \n",
       "1790935               0.000000                0.000000  \n",
       "\n",
       "[1790936 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_nest_partsavg_df = pd.merge(nestdf, partavgdf, on='ixJobSummary', how='inner')\n",
    "joined_nest_partsavg_df #avg num of parts and nest data in one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fStrategies</th>\n",
       "      <th>dPartArea_Job</th>\n",
       "      <th>dLength_Avg</th>\n",
       "      <th>dWidth_Avg</th>\n",
       "      <th>dArea_Avg</th>\n",
       "      <th>cNested_Avg</th>\n",
       "      <th>fExtShape_Avg</th>\n",
       "      <th>dExtArea_Avg</th>\n",
       "      <th>dExtBoundaryDist_Avg</th>\n",
       "      <th>dExtContainedDist_Avg</th>\n",
       "      <th>dLgIntArea_Avg</th>\n",
       "      <th>dLgIntBoundaryDist_Avg</th>\n",
       "      <th>dLgIntContainedDist_Avg</th>\n",
       "      <th>dLgExtConArea_Avg</th>\n",
       "      <th>dLgExtConBoundaryDist</th>\n",
       "      <th>dLgExtConContainedDist</th>\n",
       "      <th>CropUtil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>519.0404</td>\n",
       "      <td>11.214286</td>\n",
       "      <td>7.588371</td>\n",
       "      <td>58.148629</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18389.9746</td>\n",
       "      <td>38.347309</td>\n",
       "      <td>12.843400</td>\n",
       "      <td>475.076800</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>496.283591</td>\n",
       "      <td>6.026536</td>\n",
       "      <td>39.581636</td>\n",
       "      <td>14.593373</td>\n",
       "      <td>0.535145</td>\n",
       "      <td>2.846391</td>\n",
       "      <td>12.247745</td>\n",
       "      <td>0.341673</td>\n",
       "      <td>0.728891</td>\n",
       "      <td>0.852431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>879.9165</td>\n",
       "      <td>37.702200</td>\n",
       "      <td>20.209600</td>\n",
       "      <td>439.958200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>439.958200</td>\n",
       "      <td>9.161500</td>\n",
       "      <td>36.520700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.162600</td>\n",
       "      <td>2.761000</td>\n",
       "      <td>12.675600</td>\n",
       "      <td>0.636089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5992.2342</td>\n",
       "      <td>17.103650</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>191.540050</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>193.776600</td>\n",
       "      <td>6.589750</td>\n",
       "      <td>20.581050</td>\n",
       "      <td>0.279550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>35.632250</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.634186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>198.8594</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>198.859400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>198.859400</td>\n",
       "      <td>2.644400</td>\n",
       "      <td>37.148100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790931</th>\n",
       "      <td>0</td>\n",
       "      <td>3562.2303</td>\n",
       "      <td>52.203125</td>\n",
       "      <td>32.046875</td>\n",
       "      <td>815.453875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1175.660175</td>\n",
       "      <td>15.350675</td>\n",
       "      <td>52.728425</td>\n",
       "      <td>355.015300</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>15.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790932</th>\n",
       "      <td>4</td>\n",
       "      <td>2898.6813</td>\n",
       "      <td>23.053571</td>\n",
       "      <td>13.199986</td>\n",
       "      <td>273.049857</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>296.410943</td>\n",
       "      <td>6.052186</td>\n",
       "      <td>25.126200</td>\n",
       "      <td>3.782143</td>\n",
       "      <td>0.233057</td>\n",
       "      <td>1.326471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790933</th>\n",
       "      <td>8</td>\n",
       "      <td>1732.8873</td>\n",
       "      <td>83.057750</td>\n",
       "      <td>4.540683</td>\n",
       "      <td>288.814567</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>331.347183</td>\n",
       "      <td>2.041967</td>\n",
       "      <td>83.173917</td>\n",
       "      <td>10.515283</td>\n",
       "      <td>0.609483</td>\n",
       "      <td>2.738883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790934</th>\n",
       "      <td>8</td>\n",
       "      <td>7208.6328</td>\n",
       "      <td>43.584450</td>\n",
       "      <td>40.175350</td>\n",
       "      <td>693.526650</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1308.887900</td>\n",
       "      <td>15.457300</td>\n",
       "      <td>51.257850</td>\n",
       "      <td>504.934150</td>\n",
       "      <td>7.507200</td>\n",
       "      <td>22.396550</td>\n",
       "      <td>61.498750</td>\n",
       "      <td>1.939500</td>\n",
       "      <td>9.697650</td>\n",
       "      <td>0.509921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790935</th>\n",
       "      <td>0</td>\n",
       "      <td>1883.8126</td>\n",
       "      <td>22.099367</td>\n",
       "      <td>18.409433</td>\n",
       "      <td>313.968767</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>313.968767</td>\n",
       "      <td>7.825233</td>\n",
       "      <td>24.060967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790936 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fStrategies  dPartArea_Job  dLength_Avg  dWidth_Avg   dArea_Avg  \\\n",
       "0                  0       519.0404    11.214286    7.588371   58.148629   \n",
       "1                  8     18389.9746    38.347309   12.843400  475.076800   \n",
       "2                  8       879.9165    37.702200   20.209600  439.958200   \n",
       "3                  8      5992.2342    17.103650   18.125000  191.540050   \n",
       "4                  0       198.8594    37.000000    5.800000  198.859400   \n",
       "...              ...            ...          ...         ...         ...   \n",
       "1790931            0      3562.2303    52.203125   32.046875  815.453875   \n",
       "1790932            4      2898.6813    23.053571   13.199986  273.049857   \n",
       "1790933            8      1732.8873    83.057750    4.540683  288.814567   \n",
       "1790934            8      7208.6328    43.584450   40.175350  693.526650   \n",
       "1790935            0      1883.8126    22.099367   18.409433  313.968767   \n",
       "\n",
       "         cNested_Avg  fExtShape_Avg  dExtArea_Avg  dExtBoundaryDist_Avg  \\\n",
       "0                  1              9      0.000000              0.000000   \n",
       "1                  4              5    496.283591              6.026536   \n",
       "2                  2              0    439.958200              9.161500   \n",
       "3                 12              0    193.776600              6.589750   \n",
       "4                  1              0    198.859400              2.644400   \n",
       "...              ...            ...           ...                   ...   \n",
       "1790931            1              2   1175.660175             15.350675   \n",
       "1790932            4              3    296.410943              6.052186   \n",
       "1790933            1             16    331.347183              2.041967   \n",
       "1790934            5              0   1308.887900             15.457300   \n",
       "1790935            2             13    313.968767              7.825233   \n",
       "\n",
       "         dExtContainedDist_Avg  dLgIntArea_Avg  dLgIntBoundaryDist_Avg  \\\n",
       "0                     0.000000        0.000000                0.000000   \n",
       "1                    39.581636       14.593373                0.535145   \n",
       "2                    36.520700        0.000000                0.000000   \n",
       "3                    20.581050        0.279550                0.000000   \n",
       "4                    37.148100        0.000000                0.000000   \n",
       "...                        ...             ...                     ...   \n",
       "1790931              52.728425      355.015300                7.125000   \n",
       "1790932              25.126200        3.782143                0.233057   \n",
       "1790933              83.173917       10.515283                0.609483   \n",
       "1790934              51.257850      504.934150                7.507200   \n",
       "1790935              24.060967        0.000000                0.000000   \n",
       "\n",
       "         dLgIntContainedDist_Avg  dLgExtConArea_Avg  dLgExtConBoundaryDist  \\\n",
       "0                       0.000000           0.000000               0.000000   \n",
       "1                       2.846391          12.247745               0.341673   \n",
       "2                       0.000000          60.162600               2.761000   \n",
       "3                       0.125000          35.632250               2.375000   \n",
       "4                       0.000000           0.000000               0.000000   \n",
       "...                          ...                ...                    ...   \n",
       "1790931                15.062500           0.000000               0.000000   \n",
       "1790932                 1.326471           0.000000               0.000000   \n",
       "1790933                 2.738883           0.000000               0.000000   \n",
       "1790934                22.396550          61.498750               1.939500   \n",
       "1790935                 0.000000           0.000000               0.000000   \n",
       "\n",
       "         dLgExtConContainedDist  CropUtil  \n",
       "0                      0.000000  0.022530  \n",
       "1                      0.728891  0.852431  \n",
       "2                     12.675600  0.636089  \n",
       "3                      4.500000  0.634186  \n",
       "4                      0.000000  0.768649  \n",
       "...                         ...       ...  \n",
       "1790931                0.000000  0.262695  \n",
       "1790932                0.000000  0.640358  \n",
       "1790933                0.000000  0.617906  \n",
       "1790934                9.697650  0.509921  \n",
       "1790935                0.000000  0.648776  \n",
       "\n",
       "[1790936 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_nest_partsavg_df['CropUtil'] = joined_nest_partsavg_df['dPartArea_Job'] / joined_nest_partsavg_df['dTrueAreaRectified_Job']\n",
    "\n",
    "joined_nest_partsavg_df.drop('dLengthUsed_Avg', axis=1, inplace=True)\n",
    "joined_nest_partsavg_df.drop('dWidthUsed_Avg', axis=1, inplace=True)\n",
    "joined_nest_partsavg_df.drop('dTrueAreaRectified_Job', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "joined_nest_partsavg_df.drop('ixJobSummary', axis=1, inplace=True)\n",
    "\n",
    "joined_nest_partsavg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by strategy\n",
    "strategy_groups = joined_nest_partsavg_df.groupby('fStrategies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2147483648 (520786, 17)\n",
      "0 (692368, 17)\n",
      "1 (48044, 17)\n",
      "2 (10651, 17)\n",
      "4 (14756, 17)\n",
      "8 (218856, 17)\n",
      "16 (20268, 17)\n",
      "32 (5968, 17)\n",
      "64 (4433, 17)\n",
      "128 (16858, 17)\n",
      "256 (2465, 17)\n",
      "512 (26634, 17)\n",
      "1024 (12292, 17)\n",
      "2048 (6585, 17)\n",
      "4096 (13020, 17)\n",
      "8192 (83085, 17)\n",
      "16384 (93867, 17)\n"
     ]
    }
   ],
   "source": [
    "for strategy, group in strategy_groups:\n",
    "    print(str(strategy)+\" \"+str(group.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for models and scalers\n",
    "models = {}\n",
    "scalers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create an ANN model\n",
    "def create_ann(input_dim, learning_rate=0.001, dropout_rate=0.3, neurons=[128, 64]):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], activation='relu', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons[1], activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_absolute_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for models and scalers\n",
    "models = {}\n",
    "scalers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 780us/step - loss: 0.1658 - val_loss: 0.1265 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 786us/step - loss: 0.1310 - val_loss: 0.1220 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 793us/step - loss: 0.1274 - val_loss: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 769us/step - loss: 0.1250 - val_loss: 0.1197 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 782us/step - loss: 0.1237 - val_loss: 0.1178 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 795us/step - loss: 0.1231 - val_loss: 0.1164 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 774us/step - loss: 0.1225 - val_loss: 0.1172 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 769us/step - loss: 0.1219 - val_loss: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 754us/step - loss: 0.1216 - val_loss: 0.1167 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 771us/step - loss: 0.1178 - val_loss: 0.1111 - learning_rate: 2.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 766us/step - loss: 0.1166 - val_loss: 0.1110 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 786us/step - loss: 0.1162 - val_loss: 0.1103 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 788us/step - loss: 0.1160 - val_loss: 0.1105 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 773us/step - loss: 0.1159 - val_loss: 0.1098 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 773us/step - loss: 0.1158 - val_loss: 0.1095 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 794us/step - loss: 0.1154 - val_loss: 0.1095 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 782us/step - loss: 0.1155 - val_loss: 0.1095 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 796us/step - loss: 0.1153 - val_loss: 0.1101 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 778us/step - loss: 0.1146 - val_loss: 0.1091 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m10416/10416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 787us/step - loss: 0.1139 - val_loss: 0.1084 - learning_rate: 1.0000e-04\n",
      "\u001b[1m3255/3255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475us/step\n",
      "Strategy -2147483648 - Final ANN MAE: 0.1097107682471816\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 778us/step - loss: 0.1508 - val_loss: 0.1204 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 788us/step - loss: 0.1228 - val_loss: 0.1134 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 794us/step - loss: 0.1189 - val_loss: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 792us/step - loss: 0.1168 - val_loss: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 783us/step - loss: 0.1158 - val_loss: 0.1082 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 787us/step - loss: 0.1150 - val_loss: 0.1093 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 778us/step - loss: 0.1147 - val_loss: 0.1074 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 757us/step - loss: 0.1135 - val_loss: 0.1060 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 758us/step - loss: 0.1135 - val_loss: 0.1091 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 740us/step - loss: 0.1131 - val_loss: 0.1082 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 777us/step - loss: 0.1127 - val_loss: 0.1062 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 781us/step - loss: 0.1097 - val_loss: 0.1013 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 752us/step - loss: 0.1087 - val_loss: 0.1006 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761us/step - loss: 0.1086 - val_loss: 0.1015 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 783us/step - loss: 0.1084 - val_loss: 0.1015 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 776us/step - loss: 0.1078 - val_loss: 0.1006 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 775us/step - loss: 0.1073 - val_loss: 0.0999 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 761us/step - loss: 0.1074 - val_loss: 0.0996 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 764us/step - loss: 0.1068 - val_loss: 0.1002 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m13848/13848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 754us/step - loss: 0.1069 - val_loss: 0.0997 - learning_rate: 1.0000e-04\n",
      "\u001b[1m4328/4328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445us/step\n",
      "Strategy 0 - Final ANN MAE: 0.1004535755441663\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - loss: 0.2041 - val_loss: 0.1057 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 0.1105 - val_loss: 0.0944 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - loss: 0.0995 - val_loss: 0.0903 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - loss: 0.0966 - val_loss: 0.0899 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - loss: 0.0922 - val_loss: 0.0864 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - loss: 0.0904 - val_loss: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 0.0893 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 0.0865 - val_loss: 0.0811 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - loss: 0.0864 - val_loss: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - loss: 0.0846 - val_loss: 0.0814 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 0.0833 - val_loss: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - loss: 0.0828 - val_loss: 0.0772 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 0.0831 - val_loss: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - loss: 0.0820 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - loss: 0.0820 - val_loss: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - loss: 0.0797 - val_loss: 0.0736 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - loss: 0.0776 - val_loss: 0.0731 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - loss: 0.0771 - val_loss: 0.0731 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - loss: 0.0776 - val_loss: 0.0727 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m961/961\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - loss: 0.0773 - val_loss: 0.0732 - learning_rate: 2.0000e-04\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step\n",
      "Strategy 1 - Final ANN MAE: 0.0740200648623339\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2494 - val_loss: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.1075 - val_loss: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0838 - val_loss: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0738 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0699 - val_loss: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0618 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0576 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0555 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 0.0501 - val_loss: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0487 - val_loss: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0463 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0461 - val_loss: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0456 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - loss: 0.0446 - val_loss: 0.0403 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0461 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0461 - val_loss: 0.0403 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 0.0435 - val_loss: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 0.0457 - val_loss: 0.0384 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0450 - val_loss: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - loss: 0.0438 - val_loss: 0.0389 - learning_rate: 0.0010\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "Strategy 2 - Final ANN MAE: 0.03738127748469544\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2631 - val_loss: 0.1198 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.1328 - val_loss: 0.1069 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.1204 - val_loss: 0.0983 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.1074 - val_loss: 0.0971 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.1022 - val_loss: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0990 - val_loss: 0.0902 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0986 - val_loss: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0929 - val_loss: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0899 - val_loss: 0.0877 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0897 - val_loss: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0912 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0884 - val_loss: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - loss: 0.0872 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0856 - val_loss: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0884 - val_loss: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - loss: 0.0832 - val_loss: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0841 - val_loss: 0.0832 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - loss: 0.0837 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 0.0821 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.0837 - val_loss: 0.0821 - learning_rate: 0.0010\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n",
      "Strategy 4 - Final ANN MAE: 0.07874878821943923\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 761us/step - loss: 0.1325 - val_loss: 0.0786 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 738us/step - loss: 0.0824 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 759us/step - loss: 0.0780 - val_loss: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 751us/step - loss: 0.0758 - val_loss: 0.0687 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 745us/step - loss: 0.0746 - val_loss: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 764us/step - loss: 0.0737 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 752us/step - loss: 0.0735 - val_loss: 0.0693 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 751us/step - loss: 0.0731 - val_loss: 0.0687 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 756us/step - loss: 0.0726 - val_loss: 0.0675 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 760us/step - loss: 0.0719 - val_loss: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 743us/step - loss: 0.0718 - val_loss: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 753us/step - loss: 0.0713 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 756us/step - loss: 0.0707 - val_loss: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 755us/step - loss: 0.0706 - val_loss: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 759us/step - loss: 0.0683 - val_loss: 0.0616 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 752us/step - loss: 0.0677 - val_loss: 0.0618 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 739us/step - loss: 0.0672 - val_loss: 0.0614 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 760us/step - loss: 0.0670 - val_loss: 0.0614 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 757us/step - loss: 0.0666 - val_loss: 0.0614 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m4378/4378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 747us/step - loss: 0.0668 - val_loss: 0.0607 - learning_rate: 2.0000e-04\n",
      "\u001b[1m1368/1368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step\n",
      "Strategy 8 - Final ANN MAE: 0.06088854574044074\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2580 - val_loss: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.1206 - val_loss: 0.0961 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.1032 - val_loss: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0945 - val_loss: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0909 - val_loss: 0.0821 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0850 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 0.0857 - val_loss: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 0.0826 - val_loss: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0812 - val_loss: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0806 - val_loss: 0.0733 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - loss: 0.0788 - val_loss: 0.0741 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0791 - val_loss: 0.0722 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0767 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0767 - val_loss: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0761 - val_loss: 0.0718 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - loss: 0.0767 - val_loss: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.0743 - val_loss: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0745 - val_loss: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - loss: 0.0749 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0708 - val_loss: 0.0683 - learning_rate: 2.0000e-04\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step\n",
      "Strategy 16 - Final ANN MAE: 0.06740776591310316\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2887 - val_loss: 0.1444 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.1708 - val_loss: 0.1128 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.1483 - val_loss: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.1216 - val_loss: 0.1022 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.1200 - val_loss: 0.1004 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.1161 - val_loss: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.1106 - val_loss: 0.0933 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.1102 - val_loss: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.1034 - val_loss: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1039 - val_loss: 0.0901 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1011 - val_loss: 0.0905 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1005 - val_loss: 0.0910 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1008 - val_loss: 0.0879 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0964 - val_loss: 0.0904 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0957 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.0957 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.0952 - val_loss: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0926 - val_loss: 0.0848 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.0936 - val_loss: 0.0838 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.0913 - val_loss: 0.0831 - learning_rate: 2.0000e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step\n",
      "Strategy 32 - Final ANN MAE: 0.08809113846669805\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3677 - val_loss: 0.1718 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1824 - val_loss: 0.1279 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1520 - val_loss: 0.1218 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1377 - val_loss: 0.1132 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1241 - val_loss: 0.1133 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1212 - val_loss: 0.1065 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1157 - val_loss: 0.1019 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1126 - val_loss: 0.1019 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1102 - val_loss: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1079 - val_loss: 0.0995 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1078 - val_loss: 0.1055 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1069 - val_loss: 0.0958 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1040 - val_loss: 0.0994 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1015 - val_loss: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1006 - val_loss: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1005 - val_loss: 0.0943 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0939 - val_loss: 0.0940 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0939 - val_loss: 0.0942 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0925 - val_loss: 0.0966 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0948 - val_loss: 0.0946 - learning_rate: 2.0000e-04\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Strategy 64 - Final ANN MAE: 0.09188961986987759\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2569 - val_loss: 0.1124 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.1277 - val_loss: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.1112 - val_loss: 0.0970 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.1019 - val_loss: 0.0915 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0971 - val_loss: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0923 - val_loss: 0.0863 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0908 - val_loss: 0.0836 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0883 - val_loss: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 0.0863 - val_loss: 0.0843 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - loss: 0.0846 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 0.0829 - val_loss: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0829 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0809 - val_loss: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0808 - val_loss: 0.0766 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.0805 - val_loss: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.0808 - val_loss: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0784 - val_loss: 0.0782 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.0776 - val_loss: 0.0739 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 0.0767 - val_loss: 0.0738 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0769 - val_loss: 0.0738 - learning_rate: 2.0000e-04\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step\n",
      "Strategy 128 - Final ANN MAE: 0.07266957436902598\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4095 - val_loss: 0.1677 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2066 - val_loss: 0.1464 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1882 - val_loss: 0.1197 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1430 - val_loss: 0.1115 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1374 - val_loss: 0.0946 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1281 - val_loss: 0.0997 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1188 - val_loss: 0.0889 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1124 - val_loss: 0.0955 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1066 - val_loss: 0.0983 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1027 - val_loss: 0.0917 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1036 - val_loss: 0.0912 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0980 - val_loss: 0.0883 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0941 - val_loss: 0.0905 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1031 - val_loss: 0.0861 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0956 - val_loss: 0.0897 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0974 - val_loss: 0.0848 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1001 - val_loss: 0.0845 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0937 - val_loss: 0.0907 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0968 - val_loss: 0.0865 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0893 - val_loss: 0.0846 - learning_rate: 2.0000e-04\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Strategy 256 - Final ANN MAE: 0.08451832628498428\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - loss: 0.2167 - val_loss: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 0.1208 - val_loss: 0.1002 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 0.1078 - val_loss: 0.0984 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - loss: 0.1027 - val_loss: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.0991 - val_loss: 0.0919 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0976 - val_loss: 0.0924 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0960 - val_loss: 0.0886 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0942 - val_loss: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.0944 - val_loss: 0.0884 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - loss: 0.0928 - val_loss: 0.0888 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 0.0921 - val_loss: 0.0877 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 0.0914 - val_loss: 0.0878 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.0901 - val_loss: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - loss: 0.0901 - val_loss: 0.0864 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - loss: 0.0892 - val_loss: 0.0863 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - loss: 0.0891 - val_loss: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 0.0903 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 0.0891 - val_loss: 0.0838 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - loss: 0.0888 - val_loss: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m533/533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0886 - val_loss: 0.0847 - learning_rate: 0.0010\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step\n",
      "Strategy 512 - Final ANN MAE: 0.08299802368316325\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2974 - val_loss: 0.1178 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - loss: 0.1383 - val_loss: 0.0957 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.1223 - val_loss: 0.0881 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.1070 - val_loss: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.1059 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.1009 - val_loss: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.0937 - val_loss: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0937 - val_loss: 0.0842 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0881 - val_loss: 0.0812 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0880 - val_loss: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0845 - val_loss: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0838 - val_loss: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0817 - val_loss: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0806 - val_loss: 0.0796 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0813 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0797 - val_loss: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0817 - val_loss: 0.0759 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0792 - val_loss: 0.0761 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0788 - val_loss: 0.0759 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0749 - val_loss: 0.0747 - learning_rate: 2.0000e-04\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step\n",
      "Strategy 1024 - Final ANN MAE: 0.07359543907081563\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3678 - val_loss: 0.1285 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.1628 - val_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.1365 - val_loss: 0.0933 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.1222 - val_loss: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 0.1096 - val_loss: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.1029 - val_loss: 0.0919 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.1029 - val_loss: 0.0785 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0945 - val_loss: 0.0757 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0933 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0881 - val_loss: 0.0756 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0880 - val_loss: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0867 - val_loss: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0821 - val_loss: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.0839 - val_loss: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 0.0787 - val_loss: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0778 - val_loss: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0750 - val_loss: 0.0693 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 0.0769 - val_loss: 0.0667 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0768 - val_loss: 0.0642 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0734 - val_loss: 0.0625 - learning_rate: 2.0000e-04\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step\n",
      "Strategy 2048 - Final ANN MAE: 0.06385327250228227\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3004 - val_loss: 0.1161 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.1459 - val_loss: 0.1054 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.1272 - val_loss: 0.1008 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.1182 - val_loss: 0.0973 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.1110 - val_loss: 0.0871 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - loss: 0.1046 - val_loss: 0.0850 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0997 - val_loss: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - loss: 0.0971 - val_loss: 0.0865 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 0.0950 - val_loss: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0913 - val_loss: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0903 - val_loss: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.0882 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0879 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.0860 - val_loss: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0848 - val_loss: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0868 - val_loss: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0824 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.0825 - val_loss: 0.0744 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0812 - val_loss: 0.0735 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0819 - val_loss: 0.0731 - learning_rate: 2.0000e-04\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step\n",
      "Strategy 4096 - Final ANN MAE: 0.07603518800236708\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 830us/step - loss: 0.1738 - val_loss: 0.0992 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - loss: 0.1035 - val_loss: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - loss: 0.0948 - val_loss: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - loss: 0.0909 - val_loss: 0.0838 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.0883 - val_loss: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 0.0873 - val_loss: 0.0799 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - loss: 0.0871 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - loss: 0.0851 - val_loss: 0.0797 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.0844 - val_loss: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - loss: 0.0844 - val_loss: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - loss: 0.0811 - val_loss: 0.0754 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 0.0804 - val_loss: 0.0751 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - loss: 0.0798 - val_loss: 0.0741 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 0.0798 - val_loss: 0.0736 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - loss: 0.0796 - val_loss: 0.0737 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 0.0792 - val_loss: 0.0732 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - loss: 0.0792 - val_loss: 0.0731 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - loss: 0.0796 - val_loss: 0.0729 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - loss: 0.0785 - val_loss: 0.0723 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1662/1662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.0786 - val_loss: 0.0732 - learning_rate: 2.0000e-04\n",
      "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n",
      "Strategy 8192 - Final ANN MAE: 0.07218181656478946\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=9. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cslabwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 837us/step - loss: 0.1788 - val_loss: 0.0896 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - loss: 0.0942 - val_loss: 0.0852 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 798us/step - loss: 0.0883 - val_loss: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 800us/step - loss: 0.0859 - val_loss: 0.0821 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - loss: 0.0843 - val_loss: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 792us/step - loss: 0.0843 - val_loss: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 789us/step - loss: 0.0829 - val_loss: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 791us/step - loss: 0.0821 - val_loss: 0.0784 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 791us/step - loss: 0.0821 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 0.0814 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790us/step - loss: 0.0802 - val_loss: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 795us/step - loss: 0.0790 - val_loss: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step - loss: 0.0808 - val_loss: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796us/step - loss: 0.0786 - val_loss: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 799us/step - loss: 0.0787 - val_loss: 0.0759 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803us/step - loss: 0.0792 - val_loss: 0.0751 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step - loss: 0.0782 - val_loss: 0.0740 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 804us/step - loss: 0.0773 - val_loss: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 798us/step - loss: 0.0775 - val_loss: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m1878/1878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790us/step - loss: 0.0775 - val_loss: 0.0741 - learning_rate: 0.0010\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step\n",
      "Strategy 16384 - Final ANN MAE: 0.07263756478868126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for strategy, group in strategy_groups:\n",
    "    X = group.drop(columns=['CropUtil', 'fStrategies'])\n",
    "    y = group['CropUtil']\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train final model with best parameters\n",
    "    input_dim = X.shape[1]\n",
    "    model = create_ann(input_dim, learning_rate=0.001, dropout_rate=0.2, neurons=[128, 64])\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Strategy {strategy} - Final ANN MAE: {mae}')\n",
    "\n",
    "    # Store the models and scalers\n",
    "    models[strategy] = model\n",
    "    scalers[strategy] = scaler\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('scalers', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models, scalers, and encoders\n",
    "for strategy, group in strategy_groups:\n",
    "    # Save the regression model\n",
    "    model_path = f'models/{strategy}_rf_model.pkl'\n",
    "    joblib.dump(models[strategy], model_path)\n",
    "    \n",
    "    # Save the scaler\n",
    "    scaler_path = f'scalers/{strategy}_scaler.pkl'\n",
    "    joblib.dump(scalers[strategy], scaler_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Saved models and Check MAE and MSE for Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3255/3255\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step\n",
      "Strategy -2147483648 - ANN MAE: 0.17141690402405493\n",
      "\u001b[1m4328/4328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 449us/step\n",
      "Strategy 0 - ANN MAE: 0.02514191891341782\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n",
      "Strategy 1 - ANN MAE: 0.013655793369293621\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "Strategy 2 - ANN MAE: 0.005907572402820202\n",
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step\n",
      "Strategy 4 - ANN MAE: 0.015734189601127126\n",
      "\u001b[1m1368/1368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 487us/step\n",
      "Strategy 8 - ANN MAE: 0.010604672261677443\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step\n",
      "Strategy 16 - ANN MAE: 0.01066016896679092\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n",
      "Strategy 32 - ANN MAE: 0.01514540548180336\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Strategy 64 - ANN MAE: 0.01600299332727579\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step\n",
      "Strategy 128 - ANN MAE: 0.009791450454960068\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Strategy 256 - ANN MAE: 0.012629927302528729\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step\n",
      "Strategy 512 - ANN MAE: 0.014408496732857616\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step\n",
      "Strategy 1024 - ANN MAE: 0.013666928816760916\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "Strategy 2048 - ANN MAE: 0.010932017264043258\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step\n",
      "Strategy 4096 - ANN MAE: 0.013070337556535267\n",
      "\u001b[1m520/520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step\n",
      "Strategy 8192 - ANN MAE: 0.012215803208491714\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step\n",
      "Strategy 16384 - ANN MAE: 0.0106639314554052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for strategy, group in strategy_groups:\n",
    "    X = group.drop(columns=['CropUtil', 'fStrategies'])\n",
    "    y = group['CropUtil']\n",
    "\n",
    "    # Load the scaler\n",
    "    scaler_path = f'scalers/{strategy}_scaler.pkl'\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    model_path = f'models/{strategy}_rf_model.pkl'\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    ##\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Strategy {strategy} - ANN MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
